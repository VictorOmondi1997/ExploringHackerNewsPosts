{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "![Hacker News](https://s3.amazonaws.com/dq-content/354/hacker_news.jpg)\n",
    "This project works with a data set of submissions ot popular technology site [Hacker News](https://news.ycombinator.com/)\n",
    "\n",
    "## Brief Introduction of Hacker News\n",
    "\n",
    "[Hacker News](https://news.ycombinator.com/) is a site started by the startup incubator [Y Combinator](https://www.ycombinator.com/), where user-submited stories (known as \"post\") are voted and commented upon, similar to reddit. Hacker News is extremely popular in technology and startup circles, adn posts that make it to the top of Hacker News' listings can get hundrends of thousands of visitors as a result.\n",
    "\n",
    "# Dataset\n",
    "\n",
    "Hacker news data set can be found [here](https://www.kaggle.com/hacker-news/hacker-news-posts)\n",
    "\n",
    "> Note: the data set has been reduced from almost `300, 000` rows to approximately `20, 000` rows by removing all submissions that did not receive any comments, and then randomly sampling from the remaining submissions. \n",
    "\n",
    "## Dataset Description of the columns\n",
    "Below are the descriptions of the columns:\n",
    "\n",
    "* `id`: The unique identifier from Hacker News for the post\n",
    "* `title`: The title of the post\n",
    "* `url`: The URL that the post links to, if the post has a URL\n",
    "* `num_points`: The number of points the post acquired, calculated as the `total number of upvotes` minus the `total number of downvotes`\n",
    "* `num_comments`: The number of comments that were made on the post\n",
    "* `author`: The username of the person who submitted the post\n",
    "* `created_at`: The date and time at which the post was submitted\n",
    "\n",
    "### Dataset head\n",
    "Here are the first few rows of the data set:\n",
    "\n",
    "|id|title|url|num_points|num_comments|author|created_at|\n",
    "|---|---|---|---|---|---|---|\n",
    "||||||||\n",
    "\n",
    "Interest is on the posts whose titles begin with either `Ask HN` or `Show HN`. Users submit `Ask HN` post to ask the Hacker News community a specific question. Below are a couple of examples:\n",
    "```\n",
    "Ask HN: How to imporve my personaly website?\n",
    "Ask HN: Am I the only one outraged by Twitter shutting down share counts?\n",
    "Ask HN: Aby recent changes to CSS that broke mobile?\n",
    "```\n",
    "\n",
    "Likewise, users submit `Show HN` posts to show the Hacker News community a project, product, or just generally something interesting. Below are a couple of examples:\n",
    "```\n",
    "Show HN: Wio Link ESP8266 Based Web of Things Hardware Development Platform'\n",
    "Show HN: Something pointless I made\n",
    "Show HN: Shanhu.io, a programming playground powered by e8vm\n",
    "```\n",
    "\n",
    "The two types of posts will be compared to determine the following:\n",
    "\n",
    "* Do `Ask HN` or `Show HN` receive more comments on average?\n",
    "* Do posts created at a certain time receive more comments on average?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Importing libraries needed and reading the dataset into list of lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['id', 'title', 'url', 'num_points', 'num_comments', 'author', 'created_at'], ['12224879', 'Interactive Dynamic Video', 'http://www.interactivedynamicvideo.com/', '386', '52', 'ne0phyte', '8/4/2016 11:52'], ['10975351', 'How to Use Open Source and Shut the Fuck Up at the Same Time', 'http://hueniverse.com/2016/01/26/how-to-use-open-source-and-shut-the-fuck-up-at-the-same-time/', '39', '10', 'josep2', '1/26/2016 19:30'], ['11964716', \"Florida DJs May Face Felony for April Fools' Water Joke\", 'http://www.thewire.com/entertainment/2013/04/florida-djs-april-fools-water-joke/63798/', '2', '1', 'vezycash', '6/23/2016 22:20'], ['11919867', 'Technology ventures: From Idea to Enterprise', 'https://www.amazon.com/Technology-Ventures-Enterprise-Thomas-Byers/dp/0073523429', '3', '1', 'hswarna', '6/17/2016 0:01']]\n"
     ]
    }
   ],
   "source": [
    "hn = list(csv.reader(open('hacker_news.csv')))\n",
    "print(hn[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **NOTE:** The first list in the inner lists contains the column headers, and the lists after contain the data for one row. In order to analyze the data, the row containing the column headers needs to be removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['id', 'title', 'url', 'num_points', 'num_comments', 'author', 'created_at'] [['12224879', 'Interactive Dynamic Video', 'http://www.interactivedynamicvideo.com/', '386', '52', 'ne0phyte', '8/4/2016 11:52'], ['10975351', 'How to Use Open Source and Shut the Fuck Up at the Same Time', 'http://hueniverse.com/2016/01/26/how-to-use-open-source-and-shut-the-fuck-up-at-the-same-time/', '39', '10', 'josep2', '1/26/2016 19:30'], ['11964716', \"Florida DJs May Face Felony for April Fools' Water Joke\", 'http://www.thewire.com/entertainment/2013/04/florida-djs-april-fools-water-joke/63798/', '2', '1', 'vezycash', '6/23/2016 22:20'], ['11919867', 'Technology ventures: From Idea to Enterprise', 'https://www.amazon.com/Technology-Ventures-Enterprise-Thomas-Byers/dp/0073523429', '3', '1', 'hswarna', '6/17/2016 0:01'], ['10301696', 'Note by Note: The Making of Steinway L1037 (2007)', 'http://www.nytimes.com/2007/11/07/movies/07stein.html?_r=0', '8', '2', 'walterbell', '9/30/2015 4:12']]\n"
     ]
    }
   ],
   "source": [
    "headers = hn[0]\n",
    "hn = hn[1:]\n",
    "print(headers,hn[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data filtering\n",
    "Since the concern is on the post titles begining with `Ask HN` or `Show HN`, new lists of lists containing just the data for those titles needs to be created.\n",
    "\n",
    "In order to find the posts that begin with either `Ask HN` or `Show HN`, pythons' string method `startswith` will be used.\n",
    "\n",
    "**Example**: Given a string object, say, `string1`, we can check if it starts with, say, `dq` by inspecting the output of the object `string1.startswith('dq')`. If `string1` starts with `dq`, it will return `True`, otherwise it will return `False`\n",
    "```python\n",
    "print('dataquest'.startswith('Data'))\n",
    "print('dataquest'.startswith('data'))\n",
    "```\n",
    "\n",
    "```python\n",
    "False\n",
    "True\n",
    "```\n",
    "\n",
    "In the example above, the first print call gives `False` because `dataquest` does not start with `Data`. The second print call prints `True` because `dataquest` does start with `data`. Capitalization matters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting `Ask HN` and `Show HN` Posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ask_posts = []\n",
    "show_posts = []\n",
    "other_posts = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of posts in ask_posts: 1744\n",
      "Number of posts in show_posts: 1162\n",
      "Number of posts in other_posts 17194\n"
     ]
    }
   ],
   "source": [
    "for row in hn:\n",
    "    title = row[1]\n",
    "    if title.lower().startswith('ask hn'):\n",
    "        ask_posts.append(row)\n",
    "    elif title.lower().startswith('show hn'):\n",
    "        show_posts.append(row)\n",
    "    else:\n",
    "        other_posts.append(row)\n",
    "print('Number of posts in ask_posts:',len(ask_posts))\n",
    "print('Number of posts in show_posts:', len(show_posts))\n",
    "print('Number of posts in other_posts', len(other_posts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Below are the first five rows in the `ask_posts` list of lists:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['12296411', 'Ask HN: How to improve my personal website?', '', '2', '6', 'ahmedbaracat', '8/16/2016 9:55'], ['10610020', 'Ask HN: Am I the only one outraged by Twitter shutting down share counts?', '', '28', '29', 'tkfx', '11/22/2015 13:43'], ['11610310', 'Ask HN: Aby recent changes to CSS that broke mobile?', '', '1', '1', 'polskibus', '5/2/2016 10:14'], ['12210105', 'Ask HN: Looking for Employee #3 How do I do it?', '', '1', '3', 'sph130', '8/2/2016 14:20'], ['10394168', 'Ask HN: Someone offered to buy my browser extension from me. What now?', '', '28', '17', 'roykolak', '10/15/2015 16:38']]\n"
     ]
    }
   ],
   "source": [
    "print(ask_posts[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below are the five rows in the `show_posts` list of lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['10627194', 'Show HN: Wio Link  ESP8266 Based Web of Things Hardware Development Platform', 'https://iot.seeed.cc', '26', '22', 'kfihihc', '11/25/2015 14:03'], ['10646440', 'Show HN: Something pointless I made', 'http://dn.ht/picklecat/', '747', '102', 'dhotson', '11/29/2015 22:46'], ['11590768', 'Show HN: Shanhu.io, a programming playground powered by e8vm', 'https://shanhu.io', '1', '1', 'h8liu', '4/28/2016 18:05'], ['12178806', 'Show HN: Webscope  Easy way for web developers to communicate with Clients', 'http://webscopeapp.com', '3', '3', 'fastbrick', '7/28/2016 7:11'], ['10872799', 'Show HN: GeoScreenshot  Easily test Geo-IP based web pages', 'https://www.geoscreenshot.com/', '1', '9', 'kpsychwave', '1/9/2016 20:45']]\n"
     ]
    }
   ],
   "source": [
    "print(show_posts[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Calculating the Average Number of Comments for `Ask HN` and `Show HN` posts\n",
    "Determining if `ask_posts` or `show_posts` receive more comments on average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.038417431192661\n"
     ]
    }
   ],
   "source": [
    "total_ask_comments = 0\n",
    "for row in ask_posts:\n",
    "    num_comments = int(row[4])\n",
    "    total_ask_comments += num_comments\n",
    "avg_ask_comments = total_ask_comments/len(ask_posts)\n",
    "print(avg_ask_comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.31669535283993\n"
     ]
    }
   ],
   "source": [
    "total_show_comments = 0\n",
    "for row in show_posts:\n",
    "    num_comments = int(row[4])\n",
    "    total_show_comments += num_comments\n",
    "avg_show_comments = total_show_comments/len(show_posts)\n",
    "print(avg_show_comments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the sample, on average `ask_posts` receive more comments (`14`) than `show_posts` (`10`). This analysis will focus of `ask_posts` since it receives more comments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Finding the Amount of `ask_posts` and Coments by Hour Created\n",
    "Determining if ask posts created at a certain `time` are more likely to attract comments. The following steps will be used to perform this analysis:\n",
    "\n",
    "1. Calculate the ***amount of ask posts*** created in each hour of the day, alon with the number of comments received\n",
    "2. Calculate the ***average number of comments*** ask posts receive by hour created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import datetime as dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'00': 447,\n",
       " '01': 683,\n",
       " '02': 1381,\n",
       " '03': 421,\n",
       " '04': 337,\n",
       " '05': 464,\n",
       " '06': 397,\n",
       " '07': 267,\n",
       " '08': 492,\n",
       " '09': 251,\n",
       " '10': 793,\n",
       " '11': 641,\n",
       " '12': 687,\n",
       " '13': 1253,\n",
       " '14': 1416,\n",
       " '15': 4477,\n",
       " '16': 1814,\n",
       " '17': 1146,\n",
       " '18': 1439,\n",
       " '19': 1188,\n",
       " '20': 1722,\n",
       " '21': 1745,\n",
       " '22': 479,\n",
       " '23': 543}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_list = []\n",
    "for row in ask_posts:\n",
    "    created_at = row[6]\n",
    "    num_comments = int(row[4])\n",
    "    result_list.append([created_at,num_comments])\n",
    "counts_by_hour = {}\n",
    "comments_by_hour= {}\n",
    "for row in result_list:\n",
    "    date_created_at=dt.datetime.strptime(row[0], \"%m/%d/%Y %H:%M\")\n",
    "    hour_created_at = dt.datetime.strftime(date_created_at, '%H')\n",
    "    if hour_created_at not in counts_by_hour:\n",
    "        counts_by_hour[hour_created_at]=1\n",
    "        comments_by_hour[hour_created_at]=row[1]\n",
    "    else:\n",
    "        comments_by_hour[hour_created_at]+=row[1]\n",
    "        counts_by_hour[hour_created_at]+=1\n",
    "comments_by_hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'00': 55,\n",
       " '01': 60,\n",
       " '02': 58,\n",
       " '03': 54,\n",
       " '04': 47,\n",
       " '05': 46,\n",
       " '06': 44,\n",
       " '07': 34,\n",
       " '08': 48,\n",
       " '09': 45,\n",
       " '10': 59,\n",
       " '11': 58,\n",
       " '12': 73,\n",
       " '13': 85,\n",
       " '14': 107,\n",
       " '15': 116,\n",
       " '16': 108,\n",
       " '17': 100,\n",
       " '18': 109,\n",
       " '19': 110,\n",
       " '20': 80,\n",
       " '21': 109,\n",
       " '22': 71,\n",
       " '23': 68}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts_by_hour"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Calculating the Average Number of Comments for `Ask HN` posts by Hour\n",
    "Since:\n",
    "\n",
    "1. `counts_by_hour`: contains the number of ask posts created during each hour of the day\n",
    "2. `comments_by_hour`: contains the correstponding number of comments ask posts created at each hour received,\n",
    "\n",
    "the two dictionaries will be used to calculate the ***average number of comments*** for posts created during each hour of the day.\n",
    "\n",
    "Creating a list of lists containing the hours during which posts were created and the average number of comments those posts received"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.31669535283993"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_by_hour = []\n",
    "for hour in comments_by_hour:\n",
    "    avg_by_hour.append([hour, comments_by_hour[hour]/counts_by_hour[hour]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['21', 16.009174311926607],\n",
       " ['01', 11.383333333333333],\n",
       " ['16', 16.796296296296298],\n",
       " ['10', 13.440677966101696],\n",
       " ['08', 10.25],\n",
       " ['05', 10.08695652173913],\n",
       " ['14', 13.233644859813085],\n",
       " ['07', 7.852941176470588],\n",
       " ['09', 5.5777777777777775],\n",
       " ['04', 7.170212765957447],\n",
       " ['12', 9.41095890410959],\n",
       " ['03', 7.796296296296297],\n",
       " ['17', 11.46],\n",
       " ['13', 14.741176470588234],\n",
       " ['22', 6.746478873239437],\n",
       " ['19', 10.8],\n",
       " ['06', 9.022727272727273],\n",
       " ['11', 11.051724137931034],\n",
       " ['20', 21.525],\n",
       " ['02', 23.810344827586206],\n",
       " ['00', 8.127272727272727],\n",
       " ['23', 7.985294117647059],\n",
       " ['15', 38.5948275862069],\n",
       " ['18', 13.20183486238532]]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_by_hour"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Sorting and Printing Values from a List of Lists\n",
    "although `avg_by_hour` contains the results needed, this formart makes it hart to identify the hours with the highest values. The list needs to be sorted and identifying five highest values in a format that's easier to read."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[16.009174311926607, '21'], [11.383333333333333, '01'], [16.796296296296298, '16'], [13.440677966101696, '10'], [10.25, '08'], [10.08695652173913, '05'], [13.233644859813085, '14'], [7.852941176470588, '07'], [5.5777777777777775, '09'], [7.170212765957447, '04'], [9.41095890410959, '12'], [7.796296296296297, '03'], [11.46, '17'], [14.741176470588234, '13'], [6.746478873239437, '22'], [10.8, '19'], [9.022727272727273, '06'], [11.051724137931034, '11'], [21.525, '20'], [23.810344827586206, '02'], [8.127272727272727, '00'], [7.985294117647059, '23'], [38.5948275862069, '15'], [13.20183486238532, '18']]\n"
     ]
    }
   ],
   "source": [
    "swap_avg_by_hour = []\n",
    "for row in avg_by_hour:\n",
    "    swap_avg_by_hour.append([row[1], row[0]])\n",
    "print(swap_avg_by_hour)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[38.5948275862069, '15'],\n",
       " [23.810344827586206, '02'],\n",
       " [21.525, '20'],\n",
       " [16.796296296296298, '16'],\n",
       " [16.009174311926607, '21'],\n",
       " [14.741176470588234, '13'],\n",
       " [13.440677966101696, '10'],\n",
       " [13.233644859813085, '14'],\n",
       " [13.20183486238532, '18'],\n",
       " [11.46, '17'],\n",
       " [11.383333333333333, '01'],\n",
       " [11.051724137931034, '11'],\n",
       " [10.8, '19'],\n",
       " [10.25, '08'],\n",
       " [10.08695652173913, '05'],\n",
       " [9.41095890410959, '12'],\n",
       " [9.022727272727273, '06'],\n",
       " [8.127272727272727, '00'],\n",
       " [7.985294117647059, '23'],\n",
       " [7.852941176470588, '07'],\n",
       " [7.796296296296297, '03'],\n",
       " [7.170212765957447, '04'],\n",
       " [6.746478873239437, '22'],\n",
       " [5.5777777777777775, '09']]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_swap = sorted(swap_avg_by_hour, reverse=True)\n",
    "sorted_swap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 Hours for Ask Posts Comments\n",
      "15:00 38.59 average comments per post\n",
      "02:00 23.81 average comments per post\n",
      "20:00 21.52 average comments per post\n",
      "16:00 16.80 average comments per post\n",
      "21:00 16.01 average comments per post\n"
     ]
    }
   ],
   "source": [
    "print('Top 5 Hours for Ask Posts Comments')\n",
    "for row in sorted_swap[:5]:\n",
    "    print(\n",
    "        \"{} {:.2f} average comments per post\".format(\n",
    "            dt.datetime.strptime(row[1], '%H').strftime('%H:%M'),\n",
    "            row[0]\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The hour that receives the most comments per post on average is 15:00, with an average of 38.59 comments per post. There's about a 60% increase in the number of comments between the hours with the highest and second highest average number of comments.\n",
    "\n",
    "According to the data set [documentation](https://www.kaggle.com/hacker-news/hacker-news-posts/home), the timezone used is Eastern Time in the US. So, we could also write 15:00 as 3:00 pm est.\n",
    "\n",
    "# Conclusion\n",
    "In this project, we analyzed ask posts and show posts to determine which type of post and time receive the most comments on average. Based on our analysis, to maximize the amount of comments a post receives, we'd recommend the post be categorized as ask post and created between 15:00 and 16:00 (3:00 pm est - 4:00 pm est).\n",
    "\n",
    "However, it should be noted that the data set we analyzed excluded posts without any comments. Given that, it's more accurate to say that of the posts that received comments, ask posts received more comments on average and ask posts created between 15:00 and 16:00 (3:00 pm est - 4:00 pm est) received the most comments on average."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
